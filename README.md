## Диалоговые системы — лабораторные работы

### Лабораторная 1 — NLU: классификация интентов + NER (мультитаск)

- **Задание**: подготовить разметку слотов в BIO-формате и дообучить одну модель, решающую две задачи одновременно: классификация интента высказывания и извлечение сущностей (слотов) на уровне токенов.
- **Использованные модели/подход**: датасет `AmazonScience/massive` (сплит `de-DE`); базовый энкодер BERT `google-bert/bert-base-german-cased`; общая BERT-часть + две головы (intent-classifier и token-classifier для NER); обучение через `transformers.Trainer`, метрики — accuracy и macro-F1 для интентов, `seqeval` для NER, плюс end-to-end accuracy.
- **Результат** (тест): интенты — **Accuracy 0.8500**, **F1 0.7894**; NER — **Accuracy 0.9059**, **F1 0.7084**; end-to-end — **Accuracy 0.6184**.

### Лабораторная 2 — информационный поиск: BM25 + переранжирование Cross-Encoder

- **Задание**: построить индекс коллекции документов, реализовать базовый поиск (BM25) по текстовому запросу, затем улучшить качество выдачи переранжированием top-K документов нейросетевым ранжировщиком и оценить качество по IR-метрикам.
- **Использованные модели/инструменты**: Elasticsearch (индексация и поиск `multi_match`/BM25); двухэтапный пайплайн **BM25 (top-50) → rerank**; Cross-Encoder `cross-encoder/ms-marco-MiniLM-L-6-v2` (SentenceTransformers `CrossEncoder`); оценка через `trectools` (P@5, R@5, MAP@5, MRR@5).
- **Результат**: реализованы скрипты для индексации корпуса, генерации TREC run-файлов (baseline BM25 и вариант с переранжированием) и подсчёта метрик качества (числа зависят от входных `assets/*`).
